# SAF - Algorithmic Storage System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Test Coverage](https://img.shields.io/badge/coverage-87%25-brightgreen.svg)](https://github.com/xuyedev/saf)
[![Tests](https://img.shields.io/badge/tests-169%20passed-success.svg)](https://github.com/xuyedev/saf)

[ä¸­æ–‡æ–‡æ¡£](README_CN.md) | English

---

## ğŸ“– What is SAF?

**SAF (Scientific Algorithmic Format)** is an innovative storage system designed for scientific computing data. Instead of storing the data itself, SAF stores the **algorithm that can regenerate the data**, achieving compression ratios of **100Ã—~100,000Ã—** while maintaining **bit-level lossless** reconstruction.

### Core Insight

> Why store the computed results when you can store the algorithm that generates them?

**Traditional Compression** (gzip/zstd):
- Theory: Statistical redundancy elimination (Shannon Entropy)
- Compression ratio: 2Ã—~5Ã—
- Limitation: Cannot exploit generative patterns

**Algorithmic Storage** (SAF):
- Theory: Kolmogorov Complexity (shortest program length)
- Compression ratio: **100Ã—~100,000Ã—**
- Advantage: Discovers and stores generative rules

---

## âœ¨ Key Features

- ğŸš€ **Ultra-High Compression Ratio**: 100Ã—~100,000Ã— for pattern-rich data
- ğŸ”¬ **Automatic Pattern Detection**: Detects mathematical sequences, fractals, procedural patterns
- âœ… **Bit-Level Lossless**: 100% data integrity guaranteed (verified by hash)
- ğŸ“Š **Supports Multiple Data Types**: Sequences, fractal images, Perlin noise, 2D patterns
- âš¡ **High Performance**: Parallel processing support, 28% speedup for large files (4 threads)
- ğŸ› ï¸ **Easy to Use**: CLI commands and Python API

---

## ğŸ“Š Performance Metrics

Based on comprehensive testing (20 test cases, 100% completed):

| Metric | Value | Description |
|--------|-------|-------------|
| **Highest Compression Ratio** | **82,123Ã—** | 4K Mandelbrot fractal (31.64 MB â†’ 404 B) |
| **Average Compression Ratio** | **2,195Ã—** | Batch test (10 files) |
| **Fastest Decompression** | **6.7 ms** | Stripe pattern (1.00 MB) |
| **Maximum Data Size** | **31.64 MB** | 4K fractal image (8.3M pixels) |
| **Batch Success Rate** | **100%** | 10/10 files passed |
| **Concurrent Success Rate** | **100%** | 9/9 operations passed |
| **Concurrent Speedup** | **28%** | Large files (4 threads) |

### Example Compression Results

| Data Type | Original Size | Compressed Size | Ratio | Algorithm |
|-----------|--------------|-----------------|-------|-----------|
| Fibonacci (1M terms) | 7.63 MB | 408 B | **19,608Ã—** | fibonacci |
| Mandelbrot (4K) | 31.64 MB | 404 B | **82,123Ã—** | mandelbrot |
| Perlin Noise | 2.00 MB | 407 B | **5,153Ã—** | perlin_noise |
| Checkerboard | 1.00 MB | 363 B | **2,889Ã—** | checkerboard |
| Prime Numbers | 79 KB | 314 B | **254Ã—** | primes |

---

## ğŸ¯ Ideal Use Cases

### âœ… Perfect Fit (Compression Ratio > 100Ã—)

- Mathematical sequences (Fibonacci, primes, polynomials)
- Fractal images (Mandelbrot, Julia sets)
- Procedurally generated content (Perlin noise, checkerboard, stripes)
- Physics simulation results (following known laws)
- Parametric 3D models

### âš ï¸ Not Suitable

- Real photos (no deterministic generation algorithm)
- Natural language text (semantic complexity)
- True random data (white noise)
- Very small data (< 1KB, metadata overhead)

---

## ğŸš§ Project Status

**Current Version**: v0.2.0 (Testing & Optimization Phase)

- âœ… Core functionality complete (7/8 development stages)
- âœ… Comprehensive testing complete (20/20 tests, 169 unit tests)
- âœ… Test coverage: 87%
- âœ… Concurrent processing verified (thread-safe)
- âš ï¸ **Note**: This software is under active development. Features may change without notice. Please test thoroughly before production use.

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- pip package manager

### Install from Source

```bash
# Clone the repository
git clone https://github.com/xuyedev/saf.git
cd saf

# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install SAF
pip install -e .
```

### Verify Installation

```bash
saf --help
```

---

## ğŸš€ Quick Start

### Command Line Interface

#### 1. Compress a File

```bash
# Compress a numpy array (.npy file)
saf compress data/sequences/fibonacci_10000.npy -o output.saf

# Output:
# âœ“ Compression completed
# Algorithm: fibonacci
# Confidence: 100.0%
# Compression ratio: 198.3Ã—
# Original: 79.00 KB â†’ Compressed: 404 B
```

#### 2. Decompress a File

```bash
# Decompress .saf file
saf decompress output.saf -o restored.npy

# Output:
# âœ“ Decompression completed
# Data restored successfully
```

#### 3. Verify Lossless Integrity

```bash
# Verify data integrity
saf verify data/sequences/fibonacci_10000.npy restored.npy

# Output:
# âœ“ Verification passed
# Hash match: âœ“
# Bit-level lossless: âœ“
```

#### 4. Batch Benchmark

```bash
# Run benchmark on directory
saf benchmark data/sequences/

# Output:
# Processing 10 files...
# Average compression ratio: 2195Ã—
# Total time: 33.09s
# Success rate: 100%
```

### Python API

```python
from src.storage.compressor import Compressor
from src.storage.decompressor import Decompressor
import numpy as np

# Load data
data = np.load('data/sequences/fibonacci_10000.npy')

# Compress
compressor = Compressor()
result = compressor.compress(data, 'output.saf')
print(f"Compression ratio: {result.compression_ratio:.1f}Ã—")

# Decompress
decompressor = Decompressor()
restored_data = decompressor.decompress('output.saf')

# Verify
assert np.array_equal(data, restored_data)
print("âœ“ Bit-level lossless verified!")
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|-----------|------------|
| **Language** | Python 3.10+ |
| **Scientific Computing** | NumPy, SciPy |
| **Symbolic Computation** | SymPy |
| **CLI Framework** | Click |
| **Serialization** | msgpack |
| **Testing** | pytest, pytest-cov |
| **Progress Display** | tqdm |
| **Type Checking** | mypy |
| **Code Formatting** | black, ruff |

---

## ğŸ“ Project Structure

```
saf/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ cli/                  # Command-line interface
â”‚   â”œâ”€â”€ detectors/            # Pattern detectors
â”‚   â”œâ”€â”€ generators/           # Data generators
â”‚   â”œâ”€â”€ storage/              # Compression/decompression engine
â”‚   â”œâ”€â”€ utils/                # Utility functions
â”‚   â””â”€â”€ verification/         # Verification and benchmarking
â”œâ”€â”€ tests/                    # Test suite (169 tests, 87% coverage)
â”œâ”€â”€ data/                     # Sample data
â”œâ”€â”€ config/                   # Configuration files
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                 # This file
```

---

## ğŸ§ª Testing & Quality

- **Unit Tests**: 169 tests (100% passed)
- **Test Coverage**: 87%
- **Integration Tests**: End-to-end workflow verified
- **Concurrent Tests**: Thread-safety verified (100% success)
- **Large-Scale Tests**: 4K images (31.64 MB), 1M sequences (7.63 MB)
- **Type Checking**: mypy strict mode
- **Code Style**: PEP 8 compliant (black + ruff)

---

## âš ï¸ Known Limitations

### Performance Constraints

- **Python GIL**: Limits CPU-bound concurrent efficiency
- **Small File Overhead**: < 1KB files have high metadata overhead
- **Detection Time**: Pattern detection may take seconds for large data

### Unsupported Data Types

- Ï€ digits sequence (computation cost > storage cost)
- True random data (white noise)
- Float64 fractals (requires feature extension)

### Recommended Use Cases

- **Best**: Large-scale batch processing (> 1MB files)
- **Suitable**: Archive storage, bandwidth-limited data transfer
- **Avoid**: Real-time compression, extremely small files

---

## ğŸ“š Documentation

- [User Guide](docs/user_guide.md) - Detailed usage instructions
- [API Reference](docs/api_reference.md) - Python API documentation
- [Developer Guide](docs/developer_guide.md) - Architecture and contribution guide
- [Test Plan](æµ‹è¯•è¿›åº¦/TEST_PLAN.md) - Comprehensive test results
- [Development Stages](DEVELOPMENT_STAGES.md) - Project roadmap

---

## ğŸ’¬ Feedback & Support

This project is currently in the **testing and optimization phase**. Your feedback is valuable!

### Report Issues

- ğŸ› **Bug Reports**: Please open an issue on GitHub or contact via email
- ğŸ’¡ **Feature Requests**: Suggestions for improvement are welcome
- ğŸ“– **Documentation**: Help improve the documentation

### Contact

- **Email**: xu3033866090@gmail.com
- **å¾®ä¿¡ (WeChat)**: xuyedev
- **GitHub Issues**: [https://github.com/xuyedev/saf/issues](https://github.com/xuyedev/saf/issues)

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

**Important**: This software is under active development. Please read the development status notice in the LICENSE file before use.

---

## ğŸ™ Acknowledgments

This project is based on the theory of **Kolmogorov Complexity** and inspired by research in:

- **Kolmogorov Complexity**: Li, M., & VitÃ¡nyi, P. (2008). *An Introduction to Kolmogorov Complexity and Its Applications*. Springer.
- **Symbolic Regression**: Koza, J. R. (1992). *Genetic Programming*. MIT Press.
- **Fractal Compression**: Barnsley, M. F., & Hurd, L. P. (1993). *Fractal Image Compression*. AK Peters.

---

## ğŸ“Š Project Statistics

```
Development Stages: 7/8 completed
Lines of Code: ~8,000
Test Cases: 169 (100% passed)
Test Coverage: 87%
Supported Algorithms: 11 (fibonacci, primes, polynomial, arithmetic, geometric,
                          mandelbrot, julia, checkerboard, stripes, perlin_noise, gzip)
Maximum Compression Ratio: 82,123Ã—
Average Compression Ratio: 2,195Ã—
```

---

**Author**: å¾é‡ (Xu Ye)
**Date**: 2025-11-23
**Version**: v0.2.0

---

â­ **If you find this project useful, please consider giving it a star on GitHub!**
